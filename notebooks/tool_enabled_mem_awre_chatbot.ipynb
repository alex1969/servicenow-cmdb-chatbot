import os
import json
import requests
from typing import Dict, List, Any, Optional

from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode
from langchain.tools import Tool

# ----------------------------
# Config
# ----------------------------
SNOW_INSTANCE_URL = os.getenv("SNOW_INSTANCE_URL", "").rstrip("/")
SNOW_USERNAME = os.getenv("SNOW_USERNAME")
SNOW_PASSWORD = os.getenv("SNOW_PASSWORD")
SNOW_OAUTH_TOKEN = os.getenv("SNOW_OAUTH_TOKEN")  # optional OAuth

# ----------------------------
# ServiceNow CMDB tool
# ----------------------------
def _snow_headers() -> Dict[str, str]:
    headers = {"Accept": "application/json"}
    if SNOW_OAUTH_TOKEN:
        headers["Authorization"] = f"Bearer {SNOW_OAUTH_TOKEN}"
    return headers

def _snow_auth():
    if SNOW_OAUTH_TOKEN:
        return None  # OAuth via header
    return (SNOW_USERNAME, SNOW_PASSWORD)

def search_app_portfolio(query: str, department: Optional[str] = None) -> Dict[str, Any]:
    """
    Search application portfolio in ServiceNow CMDB using a natural-language query.
    Maps query to fields like name, category, owner, cost, department.
    Adjust table and fields per your SNOW schema (examples below).
    """
    if not SNOW_INSTANCE_URL:
        return {"error": "Missing SNOW_INSTANCE_URL"}

    # Example table and fields (adjust to your environment):
    # Table could be: 'cmdb_ci_appl' or a custom 'x_portfolio_application'
    table = "cmdb_ci_appl"
    url = f"{SNOW_INSTANCE_URL}/api/now/table/{table}"

    # Construct a flexible encoded query; tune for your schema and indexing
    # Example fields: name, short_description, owned_by, support_group, install_status, department, cost_center, total_cost
    q_parts = []
    if department:
        q_parts.append(f"departmentLIKES{department}")
    # Basic LIKE against name/description to match the user's intent
    q_parts.append(f"nameLIKES{query}")
    q_parts.append(f"short_descriptionLIKES{query}")
    encoded_query = "^OR".join(q_parts)

    params = {
        "sysparm_query": encoded_query,
        "sysparm_fields": "sys_id,name,short_description,owned_by,department,cost_center,total_cost,install_status,manufacturer,category",
        "sysparm_limit": "10"
    }

    try:
        resp = requests.get(url, headers=_snow_headers(), params=params, auth=_snow_auth(), timeout=15)
        resp.raise_for_status()
    except requests.RequestException as e:
        return {"error": f"ServiceNow request failed: {e}"}

    data = resp.json().get("result", [])
    results = []
    for r in data:
        results.append({
            "id": r.get("sys_id"),
            "name": r.get("name"),
            "description": r.get("short_description"),
            "application_owner": r.get("owned_by"),
            "department": r.get("department"),
            "cost_center": r.get("cost_center"),
            "estimated_cost": r.get("total_cost"),
            "status": r.get("install_status"),
            "category": r.get("category"),
            "manufacturer": r.get("manufacturer"),
            "source": f"{SNOW_INSTANCE_URL}/nav_to.do?uri={table}.do?sys_id={r.get('sys_id')}"
        })
    return {"results": results}

def snow_portfolio_tool_callable(input_text: str) -> str:
    """
    Parse minimal structure from the user's input to include department when present.
    For production, replace with a function-calling schema or a router prompt.
    """
    dept = None
    # naive department extraction
    for key in ["department ", "in my department", "for my department"]:
        if key in input_text.lower():
            # heuristic: find word after 'department' (optional)
            dept = None  # keep simple; rely on follow-up questions for precision
            break

    res = search_app_portfolio(query=input_text, department=dept)
    return json.dumps(res, ensure_ascii=False)

snow_portfolio_tool = Tool(
    name="servicenow_cmdb_app_portfolio_search",
    description="Search ServiceNow CMDB application portfolio for owners, costs, and details. Input: user query text.",
    func=snow_portfolio_tool_callable
)

tools = [snow_portfolio_tool]

# ----------------------------
# Chat model with tool binding
# ----------------------------
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)  # choose an org-approved ChatGPT-capable model
llm_with_tools = llm.bind_tools(tools)

# ----------------------------
# State and nodes
# ----------------------------
from typing import TypedDict

class ChatState(TypedDict):
    messages: List[Dict[str, Any]]

def chatbot_node(state: ChatState) -> ChatState:
    """
    Core chatbot node. The LLM chooses to call tools via tool binding.
    """
    response = llm_with_tools.invoke(state["messages"])
    return {"messages": state["messages"] + [response]}

tool_node = ToolNode(tools=tools)

# ----------------------------
# Tool condition
# ----------------------------
def tools_condition(state: ChatState) -> str:
    """
    Route to tools if the last message is a tool call; otherwise end or return to chatbot.
    LangGraph's ToolNode expects function-call style outputs; this simple condition checks message type.
    """
    last = state["messages"][-1]
    if last.get("tool_calls"):
        return "tools"
    # If the assistant already answered without tool calls, end
    return END

# ----------------------------
# Build graph
# ----------------------------
graph = StateGraph(ChatState)
graph.add_node("chatbot", chatbot_node)
graph.add_node("tools", tool_node)

graph.add_conditional_edges("chatbot", tools_condition, {"tools": "tools", END: END})
graph.add_edge("tools", "chatbot")
graph.set_entry_point("chatbot")

# ----------------------------
# Memory and compilation
# ----------------------------
memory = MemorySaver()
app = graph.compile(checkpointer=memory)

# ----------------------------
# Streaming utility
# ----------------------------
def stream_app_response(user_input: str, thread_id: str = "portfolio_query"):
    """
    Stream events for a single conversational session with memory.
    """
    config = {"configurable": {"thread_id": thread_id}}
    for event in app.stream({"messages": [{"role": "user", "content": user_input}]}, config=config):
        vals = event.values()
        if "messages" in vals:
            last = vals["messages"][-1]
            if last.get("role") == "assistant":
                print(last.get("content"))

# ----------------------------
# Example usage
# ----------------------------
if __name__ == "__main__":
    # Initial query: department-anchored request for project management software
    q1 = "What project management software is available for my team to use in my department? Include application owner, any costs, and other pertinent information."
    stream_app_response(q1, thread_id="dept_pm_tools")

    # Follow-up: narrow scope or request more details (memory preserves context)
    q2 = "Filter to options with active status and show cost centers."
    stream_app_response(q2, thread_id="dept_pm_tools")
